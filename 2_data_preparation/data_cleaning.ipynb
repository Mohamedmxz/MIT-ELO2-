{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518024fd",
   "metadata": {},
   "source": [
    "# Clean and Prepare Sudan Climate Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "To support the ELO2 project’s goal of analyzing climate patterns in Sudan, this notebook focuses on **cleaning and preparing temperature and rainfall datasets** collected from the [NASA POWER Data Access Viewer](https://power.larc.nasa.gov/).\n",
    "\n",
    "Five regional datasets were selected to represent distinct climate zones:\n",
    "- **North:** Desert zone (Dongola)\n",
    "- **Central:** Semi-arid zone (Khartoum, Gezira)\n",
    "- **East:** Coastal and semi-arid zone (Kassala, Port Sudan)\n",
    "- **West:** Transitional zone (El Obeid, Darfur)\n",
    "- **South:** Wetter zone (Blue Nile, South Kordofan)\n",
    "\n",
    "Each region has four CSV files:\n",
    "- Average temperature (`T2M`)\n",
    "- Minimum temperature (`T2M_MIN`)\n",
    "- Maximum temperature (`T2M_MAX`)\n",
    "- Precipitation (`PRECTOT`)\n",
    "\n",
    "In total, there are 20 raw files.\n",
    "\n",
    "---\n",
    "\n",
    "## Cleaning and Preparation Strategy\n",
    "\n",
    "Each dataset contains **monthly climate observations** for a given region and variable.  \n",
    "Our cleaning process will:\n",
    "\n",
    "1. **Load all CSV files** from the `Raw_datasets` folder.  \n",
    "2. **Inspect** column names, date formats, and value ranges.  \n",
    "3. **Clean** data by renaming inconsistent headers, parsing dates, and handling missing or invalid values.  \n",
    "4. **Standardize** structure across all files (columns, units, and metadata).  \n",
    "5. **Merge** datasets for further analysis by variable or by region.  \n",
    "6. **Export** cleaned data to `cleaned_datasets` folder for use in Milestone 3 (Analysis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41faabb4",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4ed79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 raw CSV files:\n",
      "- central_precip.csv\n",
      "- central_t2m.csv\n",
      "- central_t2mmax.csv\n",
      "- central_t2mmin.csv\n",
      "- east_precip.csv\n",
      "- east_t2m.csv\n",
      "- east_t2mmax.csv\n",
      "- east_t2mmin.csv\n",
      "- north_precip.csv\n",
      "- north_t2m.csv\n",
      "- north_t2mmax.csv\n",
      "- north_t2mmin.csv\n",
      "- south_precip.csv\n",
      "- south_t2m.csv\n",
      "- south_t2mmax.csv\n",
      "- south_t2mmin.csv\n",
      "- west_precip.csv\n",
      "- west_t2m.csv\n",
      "- west_t2mmax.csv\n",
      "- west_t2mmin.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to the folder containing the raw CSV files\n",
    "data_path = \"../1_datasets/Raw_datasets\"  \n",
    "\n",
    "# Get all CSV file paths from the folder\n",
    "files = glob.glob(os.path.join(data_path, \"*.csv\"))\n",
    "\n",
    "# Display how many files were found and their names\n",
    "print(f\"Found {len(files)} raw CSV files:\")\n",
    "for f in files:\n",
    "    print(\"-\", os.path.basename(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e5084",
   "metadata": {},
   "source": [
    "### Reading NASA POWER Files with Metadata\n",
    "\n",
    "NASA POWER climate datasets include descriptive metadata at the top of each file before the actual data table starts.  \n",
    "If loaded directly with `pandas.read_csv`, these metadata lines cause parsing errors because they don't follow standard CSV structure.\n",
    "\n",
    "To handle this, we define a **custom loader function** that:\n",
    "1. Reads the file as plain text.\n",
    "2. Detects the first line that contains real table headers (e.g., \"YEAR\", \"PARAMETER\", \"LAT\", \"LON\").\n",
    "3. Reads the file from that line onward into a clean `DataFrame`.\n",
    "\n",
    "This ensures every file is parsed correctly, even when metadata length or format varies slightly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd1537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to parse: ../1_datasets/Raw_datasets\\central_t2mmax.csv\n",
      "Parsed shape: (1050, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARAMETER</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUN</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AUG</th>\n",
       "      <th>SEP</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DEC</th>\n",
       "      <th>ANN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2M_MAX</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.250</td>\n",
       "      <td>35.87</td>\n",
       "      <td>35.31</td>\n",
       "      <td>38.36</td>\n",
       "      <td>44.11</td>\n",
       "      <td>43.93</td>\n",
       "      <td>43.28</td>\n",
       "      <td>40.14</td>\n",
       "      <td>40.44</td>\n",
       "      <td>41.39</td>\n",
       "      <td>41.22</td>\n",
       "      <td>39.57</td>\n",
       "      <td>38.55</td>\n",
       "      <td>44.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2M_MAX</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.875</td>\n",
       "      <td>36.47</td>\n",
       "      <td>35.64</td>\n",
       "      <td>38.90</td>\n",
       "      <td>44.80</td>\n",
       "      <td>44.46</td>\n",
       "      <td>43.14</td>\n",
       "      <td>39.96</td>\n",
       "      <td>40.35</td>\n",
       "      <td>40.88</td>\n",
       "      <td>41.57</td>\n",
       "      <td>40.13</td>\n",
       "      <td>39.22</td>\n",
       "      <td>44.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T2M_MAX</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.500</td>\n",
       "      <td>36.38</td>\n",
       "      <td>35.32</td>\n",
       "      <td>38.69</td>\n",
       "      <td>43.91</td>\n",
       "      <td>44.14</td>\n",
       "      <td>42.40</td>\n",
       "      <td>38.28</td>\n",
       "      <td>39.42</td>\n",
       "      <td>40.83</td>\n",
       "      <td>41.55</td>\n",
       "      <td>39.71</td>\n",
       "      <td>38.75</td>\n",
       "      <td>44.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2M_MAX</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.125</td>\n",
       "      <td>37.68</td>\n",
       "      <td>36.76</td>\n",
       "      <td>40.15</td>\n",
       "      <td>44.91</td>\n",
       "      <td>44.95</td>\n",
       "      <td>42.98</td>\n",
       "      <td>38.70</td>\n",
       "      <td>39.35</td>\n",
       "      <td>41.60</td>\n",
       "      <td>42.38</td>\n",
       "      <td>40.54</td>\n",
       "      <td>40.31</td>\n",
       "      <td>44.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2M_MAX</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.750</td>\n",
       "      <td>37.08</td>\n",
       "      <td>36.27</td>\n",
       "      <td>39.51</td>\n",
       "      <td>43.45</td>\n",
       "      <td>43.81</td>\n",
       "      <td>41.65</td>\n",
       "      <td>37.12</td>\n",
       "      <td>37.13</td>\n",
       "      <td>39.22</td>\n",
       "      <td>41.05</td>\n",
       "      <td>39.93</td>\n",
       "      <td>39.91</td>\n",
       "      <td>43.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PARAMETER  YEAR   LAT     LON    JAN    FEB    MAR    APR    MAY    JUN  \\\n",
       "0   T2M_MAX  1990  14.0  31.250  35.87  35.31  38.36  44.11  43.93  43.28   \n",
       "1   T2M_MAX  1990  14.0  31.875  36.47  35.64  38.90  44.80  44.46  43.14   \n",
       "2   T2M_MAX  1990  14.0  32.500  36.38  35.32  38.69  43.91  44.14  42.40   \n",
       "3   T2M_MAX  1990  14.0  33.125  37.68  36.76  40.15  44.91  44.95  42.98   \n",
       "4   T2M_MAX  1990  14.0  33.750  37.08  36.27  39.51  43.45  43.81  41.65   \n",
       "\n",
       "     JUL    AUG    SEP    OCT    NOV    DEC    ANN  \n",
       "0  40.14  40.44  41.39  41.22  39.57  38.55  44.11  \n",
       "1  39.96  40.35  40.88  41.57  40.13  39.22  44.80  \n",
       "2  38.28  39.42  40.83  41.55  39.71  38.75  44.14  \n",
       "3  38.70  39.35  41.60  42.38  40.54  40.31  44.95  \n",
       "4  37.12  37.13  39.22  41.05  39.93  39.91  43.81  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "def read_nasa_power_csv(path, header_markers=(\"PARAMETER\", \"YEAR\", \"lat\")):\n",
    "    \"\"\"\n",
    "    Read NASA POWER CSV-like files that contain a metadata block before the real table.\n",
    "    The function scans the file for a line containing one of header_markers, treats that\n",
    "    as the header line, and loads the CSV from there.\n",
    "    Returns a DataFrame.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # find header line index: look for a line that contains commas and the keyword 'YEAR' or 'PARAMETER'\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        low = line.lower()\n",
    "        if (\",\" in line) and any(h.lower() in low for h in header_markers):\n",
    "            header_idx = i\n",
    "            break\n",
    "\n",
    "    if header_idx is None:\n",
    "        # fallback: try to find the first line that looks like CSV (has many commas)\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.count(\",\") >= 3:\n",
    "                header_idx = i\n",
    "                break\n",
    "\n",
    "    if header_idx is None:\n",
    "        raise ValueError(f\"Could not detect header line in {path!r}\")\n",
    "\n",
    "    # join the rest of the file from header_idx and read with pandas\n",
    "    data_str = \"\".join(lines[header_idx:])\n",
    "    df = pd.read_csv(io.StringIO(data_str), sep=\",\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "    return df\n",
    "\n",
    "# test on the sample file\n",
    "sample_file = [f for f in files if \"central_t2mmax\" in f][0]\n",
    "print(\"Trying to parse:\", sample_file)\n",
    "df_sample = read_nasa_power_csv(sample_file)\n",
    "print(\"Parsed shape:\", df_sample.shape)\n",
    "display(df_sample.head(5))\n",
    "print(\"Columns:\", df_sample.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe063cb7",
   "metadata": {},
   "source": [
    "### Load Raw NASA POWER Datasets\n",
    "\n",
    "In this step, we load all the CSV files from the `Raw_datasets` folder using our custom function.  \n",
    "Each file contains temperature or rainfall data for different coordinates across Sudan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532a6516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded central_precip.csv | Shape: (1050, 17)\n",
      "Loaded central_t2m.csv | Shape: (1050, 17)\n",
      "Loaded central_t2mmax.csv | Shape: (1050, 17)\n",
      "Loaded central_t2mmin.csv | Shape: (1050, 17)\n",
      "Loaded east_precip.csv | Shape: (980, 17)\n",
      "Loaded east_t2m.csv | Shape: (980, 17)\n",
      "Loaded east_t2mmax.csv | Shape: (980, 17)\n",
      "Loaded east_t2mmin.csv | Shape: (980, 17)\n",
      "Loaded north_precip.csv | Shape: (1715, 17)\n",
      "Loaded north_t2m.csv | Shape: (1715, 17)\n",
      "Loaded north_t2mmax.csv | Shape: (1715, 17)\n",
      "Loaded north_t2mmin.csv | Shape: (1715, 17)\n",
      "Loaded south_precip.csv | Shape: (1225, 17)\n",
      "Loaded south_t2m.csv | Shape: (1225, 17)\n",
      "Loaded south_t2mmax.csv | Shape: (1225, 17)\n",
      "Loaded south_t2mmin.csv | Shape: (1225, 17)\n",
      "Loaded west_precip.csv | Shape: (1715, 17)\n",
      "Loaded west_t2m.csv | Shape: (1715, 17)\n",
      "Loaded west_t2mmax.csv | Shape: (1715, 17)\n",
      "Loaded west_t2mmin.csv | Shape: (1715, 17)\n",
      "\n",
      " Preview of central_precip.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARAMETER</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUN</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AUG</th>\n",
       "      <th>SEP</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DEC</th>\n",
       "      <th>ANN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRECTOTCORR</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.24</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PARAMETER  YEAR   LAT     LON  JAN  FEB  MAR  APR   MAY   JUN   JUL  \\\n",
       "0  PRECTOTCORR  1990  14.0  31.250  0.0  0.0  0.0  0.0  0.00  0.05  3.18   \n",
       "1  PRECTOTCORR  1990  14.0  31.875  0.0  0.0  0.0  0.0  0.00  0.05  3.26   \n",
       "2  PRECTOTCORR  1990  14.0  32.500  0.0  0.0  0.0  0.0  0.00  0.04  2.84   \n",
       "3  PRECTOTCORR  1990  14.0  33.125  0.0  0.0  0.0  0.0  0.01  0.05  2.69   \n",
       "4  PRECTOTCORR  1990  14.0  33.750  0.0  0.0  0.0  0.0  0.01  0.11  3.24   \n",
       "\n",
       "    AUG   SEP   OCT  NOV  DEC   ANN  \n",
       "0  0.85  0.49  0.18  0.0  0.0  0.40  \n",
       "1  0.93  0.54  0.24  0.0  0.0  0.42  \n",
       "2  1.16  0.88  0.76  0.0  0.0  0.48  \n",
       "3  1.31  1.08  1.12  0.0  0.0  0.53  \n",
       "4  1.61  1.46  1.41  0.0  0.0  0.66  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load all NASA POWER CSV files from the Raw_datasets folder ---\n",
    "import os\n",
    "\n",
    "raw_folder = \"../1_datasets/Raw_datasets\" \n",
    "\n",
    "datasets = {}\n",
    "for filename in os.listdir(raw_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        path = os.path.join(raw_folder, filename)\n",
    "        try:\n",
    "            df = read_nasa_power_csv(path)\n",
    "            datasets[filename] = df\n",
    "            print(f\"Loaded {filename} | Shape: {df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read {filename}: {e}\")\n",
    "\n",
    "# --- Preview one dataset ---\n",
    "if datasets:\n",
    "    first_name = list(datasets.keys())[0]\n",
    "    print(f\"\\n Preview of {first_name}:\")\n",
    "    display(datasets[first_name].head())\n",
    "else:\n",
    "    print(\"No datasets loaded. Check folder path or file types.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bae3a7",
   "metadata": {},
   "source": [
    "### Inspect and Profile Each Dataset\n",
    "\n",
    "Now that all datasets are loaded, we inspect their structure and quality.  \n",
    "We will:\n",
    "- Check column names and data types.  \n",
    "- Look for missing or invalid values.  \n",
    "- Verify that all datasets share the same schema (PARAMETER, YEAR, LAT, LON, JAN–DEC, ANN).  \n",
    "\n",
    "This step helps confirm data consistency before cleaning or merging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65eb5020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "central_precip.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1050, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count      mean     min     max\n",
      "PARAMETER    1050       NaN     NaN     NaN\n",
      "YEAR       1050.0    2007.0  1990.0  2024.0\n",
      "LAT        1050.0     15.25    14.0    16.5\n",
      "LON        1050.0      32.5   31.25   33.75\n",
      "JAN        1050.0  0.000457     0.0    0.06\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "central_t2m.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1050, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1050        NaN     NaN     NaN\n",
      "YEAR       1050.0     2007.0  1990.0  2024.0\n",
      "LAT        1050.0      15.25    14.0    16.5\n",
      "LON        1050.0       32.5   31.25   33.75\n",
      "JAN        1050.0  22.164848    16.2   27.53\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "central_t2mmax.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1050, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1050        NaN     NaN     NaN\n",
      "YEAR       1050.0     2007.0  1990.0  2024.0\n",
      "LAT        1050.0      15.25    14.0    16.5\n",
      "LON        1050.0       32.5   31.25   33.75\n",
      "JAN        1050.0  36.341695   28.94    41.6\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "central_t2mmin.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1050, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1050        NaN     NaN     NaN\n",
      "YEAR       1050.0     2007.0  1990.0  2024.0\n",
      "LAT        1050.0      15.25    14.0    16.5\n",
      "LON        1050.0       32.5   31.25   33.75\n",
      "JAN        1050.0  10.217562    3.62   17.45\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "east_precip.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (980, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "           count      mean     min     max\n",
      "PARAMETER    980       NaN     NaN     NaN\n",
      "YEAR       980.0    2007.0  1990.0  2024.0\n",
      "LAT        980.0      17.5    16.0    19.0\n",
      "LON        980.0   35.9375    35.0  36.875\n",
      "JAN        980.0  0.039939     0.0    2.59\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "east_t2m.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (980, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "           count       mean     min     max\n",
      "PARAMETER    980        NaN     NaN     NaN\n",
      "YEAR       980.0     2007.0  1990.0  2024.0\n",
      "LAT        980.0       17.5    16.0    19.0\n",
      "LON        980.0    35.9375    35.0  36.875\n",
      "JAN        980.0  22.717245   15.86    26.8\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "east_t2mmax.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (980, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "           count       mean     min     max\n",
      "PARAMETER    980        NaN     NaN     NaN\n",
      "YEAR       980.0     2007.0  1990.0  2024.0\n",
      "LAT        980.0       17.5    16.0    19.0\n",
      "LON        980.0    35.9375    35.0  36.875\n",
      "JAN        980.0  35.809184   27.25   40.88\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "east_t2mmin.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (980, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "           count       mean     min     max\n",
      "PARAMETER    980        NaN     NaN     NaN\n",
      "YEAR       980.0     2007.0  1990.0  2024.0\n",
      "LAT        980.0       17.5    16.0    19.0\n",
      "LON        980.0    35.9375    35.0  36.875\n",
      "JAN        980.0  11.130582    3.89   16.87\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "north_precip.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1715, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count      mean     min     max\n",
      "PARAMETER    1715       NaN     NaN     NaN\n",
      "YEAR       1715.0    2007.0  1990.0  2024.0\n",
      "LAT        1715.0      18.5    17.0    20.0\n",
      "LON        1715.0      30.0  28.125  31.875\n",
      "JAN        1715.0  0.000321     0.0    0.08\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "north_t2m.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1715, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1715        NaN     NaN     NaN\n",
      "YEAR       1715.0     2007.0  1990.0  2024.0\n",
      "LAT        1715.0       18.5    17.0    20.0\n",
      "LON        1715.0       30.0  28.125  31.875\n",
      "JAN        1715.0  16.735504   10.78   22.52\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "north_t2mmax.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1715, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count      mean     min     max\n",
      "PARAMETER    1715       NaN     NaN     NaN\n",
      "YEAR       1715.0    2007.0  1990.0  2024.0\n",
      "LAT        1715.0      18.5    17.0    20.0\n",
      "LON        1715.0      30.0  28.125  31.875\n",
      "JAN        1715.0  31.91291    22.4   39.27\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "north_t2mmin.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1715, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count      mean     min     max\n",
      "PARAMETER    1715       NaN     NaN     NaN\n",
      "YEAR       1715.0    2007.0  1990.0  2024.0\n",
      "LAT        1715.0      18.5    17.0    20.0\n",
      "LON        1715.0      30.0  28.125  31.875\n",
      "JAN        1715.0  5.430869    0.06   10.65\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "south_precip.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1225, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count      mean     min     max\n",
      "PARAMETER    1225       NaN     NaN     NaN\n",
      "YEAR       1225.0    2007.0  1990.0  2024.0\n",
      "LAT        1225.0      10.5     9.0    12.0\n",
      "LON        1225.0    30.625  29.375  31.875\n",
      "JAN        1225.0  0.002996     0.0     0.1\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "south_t2m.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1225, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1225        NaN     NaN     NaN\n",
      "YEAR       1225.0     2007.0  1990.0  2024.0\n",
      "LAT        1225.0       10.5     9.0    12.0\n",
      "LON        1225.0     30.625  29.375  31.875\n",
      "JAN        1225.0  26.426131   19.06   30.76\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "south_t2mmax.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1225, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1225        NaN     NaN     NaN\n",
      "YEAR       1225.0     2007.0  1990.0  2024.0\n",
      "LAT        1225.0       10.5     9.0    12.0\n",
      "LON        1225.0     30.625  29.375  31.875\n",
      "JAN        1225.0  38.928147   30.27   43.88\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "south_t2mmin.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1225, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1225        NaN     NaN     NaN\n",
      "YEAR       1225.0     2007.0  1990.0  2024.0\n",
      "LAT        1225.0       10.5     9.0    12.0\n",
      "LON        1225.0     30.625  29.375  31.875\n",
      "JAN        1225.0  15.288629    6.38   21.19\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "west_precip.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1715, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count      mean     min     max\n",
      "PARAMETER    1715       NaN     NaN     NaN\n",
      "YEAR       1715.0    2007.0  1990.0  2024.0\n",
      "LAT        1715.0      12.5    11.0    14.0\n",
      "LON        1715.0    26.875    25.0   28.75\n",
      "JAN        1715.0  0.000017     0.0    0.01\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "west_t2m.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1715, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1715        NaN     NaN     NaN\n",
      "YEAR       1715.0     2007.0  1990.0  2024.0\n",
      "LAT        1715.0       12.5    11.0    14.0\n",
      "LON        1715.0     26.875    25.0   28.75\n",
      "JAN        1715.0  21.715312   15.67   28.18\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "west_t2mmax.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1715, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count       mean     min     max\n",
      "PARAMETER    1715        NaN     NaN     NaN\n",
      "YEAR       1715.0     2007.0  1990.0  2024.0\n",
      "LAT        1715.0       12.5    11.0    14.0\n",
      "LON        1715.0     26.875    25.0   28.75\n",
      "JAN        1715.0  36.355026   29.13   42.05\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n",
      "west_t2mmin.csv\n",
      "------------------------------------------------------------\n",
      "Shape: (1715, 17)\n",
      "Columns: ['PARAMETER', 'YEAR', 'LAT', 'LON', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANN']\n",
      "            count      mean     min     max\n",
      "PARAMETER    1715       NaN     NaN     NaN\n",
      "YEAR       1715.0    2007.0  1990.0  2024.0\n",
      "LAT        1715.0      12.5    11.0    14.0\n",
      "LON        1715.0    26.875    25.0   28.75\n",
      "JAN        1715.0  9.567988    1.53   16.76\n",
      "\n",
      "Missing values per column:\n",
      "PARAMETER    0\n",
      "YEAR         0\n",
      "LAT          0\n",
      "LON          0\n",
      "JAN          0\n",
      "FEB          0\n",
      "MAR          0\n",
      "APR          0\n",
      "MAY          0\n",
      "JUN          0\n",
      "JUL          0\n",
      "AUG          0\n",
      "SEP          0\n",
      "OCT          0\n",
      "NOV          0\n",
      "DEC          0\n",
      "ANN          0\n",
      "dtype: int64\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, df in datasets.items():\n",
    "    print(f\"{name}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(df.describe(include='all').T[['count', 'mean', 'min', 'max']].head(5))\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"=\" * 60, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd439d",
   "metadata": {},
   "source": [
    "### Merge Regional Datasets into National-Level Files\n",
    "\n",
    "Each region of Sudan (Central, North, East, South, and West) has its own temperature and precipitation datasets.  \n",
    "In this step, we merge them into two complete national-level datasets:\n",
    "- **Temperature dataset** — combines all T2M (Temperature at 2 Meters) files.\n",
    "- **Precipitation dataset** — combines all PRECTOT (Rainfall) files.\n",
    "\n",
    "Each record will include a new column `REGION` indicating the source region.  \n",
    "The merged datasets will be saved in the `Cleaned_datasets` folder for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40ef67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged temperature data: ../1_datasets/Cleaned_datasets\\merged_temperature.csv (20055 rows)\n",
      "Saved merged precipitation data: ../1_datasets/Cleaned_datasets\\merged_precipitation.csv (6685 rows)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_folder = \"../1_datasets/Raw_datasets\"\n",
    "clean_folder = \"../1_datasets/Cleaned_datasets\"\n",
    "\n",
    "os.makedirs(clean_folder, exist_ok=True)\n",
    "\n",
    "merged_temp = []\n",
    "merged_precip = []\n",
    "\n",
    "for filename in os.listdir(raw_folder):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "    \n",
    "    path = os.path.join(raw_folder, filename)\n",
    "    df = read_nasa_power_csv(path)\n",
    "\n",
    "    # Extract region name from filename (e.g., \"central_t2m.csv\" -> \"Central\")\n",
    "    region = filename.split(\"_\")[0].capitalize()\n",
    "    df[\"REGION\"] = region\n",
    "\n",
    "    # Separate temperature and precipitation\n",
    "    if \"t2m\" in filename.lower():\n",
    "        merged_temp.append(df)\n",
    "    elif \"precip\" in filename.lower():\n",
    "        merged_precip.append(df)\n",
    "\n",
    "# Concatenate all temperature and precipitation data\n",
    "df_temp = pd.concat(merged_temp, ignore_index=True)\n",
    "df_precip = pd.concat(merged_precip, ignore_index=True)\n",
    "\n",
    "# Save merged files\n",
    "temp_path = os.path.join(clean_folder, \"merged_temperature.csv\")\n",
    "precip_path = os.path.join(clean_folder, \"merged_precipitation.csv\")\n",
    "\n",
    "df_temp.to_csv(temp_path, index=False)\n",
    "df_precip.to_csv(precip_path, index=False)\n",
    "\n",
    "print(f\"Saved merged temperature data: {temp_path} ({df_temp.shape[0]} rows)\")\n",
    "print(f\"Saved merged precipitation data: {precip_path} ({df_precip.shape[0]} rows)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b6c3c",
   "metadata": {},
   "source": [
    "### Step 1: Check and fix data types\n",
    "\n",
    "Before analysis, we must ensure all columns have correct types — YEAR as integer, REGION as string, and all months as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc27cf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types fixed.\n",
      "\n",
      "Temperature data types:\n",
      "PARAMETER     object\n",
      "YEAR           int32\n",
      "LAT          float64\n",
      "LON          float64\n",
      "JAN          float64\n",
      "FEB          float64\n",
      "MAR          float64\n",
      "APR          float64\n",
      "MAY          float64\n",
      "JUN          float64\n",
      "dtype: object\n",
      "\n",
      "Rainfall data types:\n",
      "PARAMETER     object\n",
      "YEAR           int32\n",
      "LAT          float64\n",
      "LON          float64\n",
      "JAN          float64\n",
      "FEB          float64\n",
      "MAR          float64\n",
      "APR          float64\n",
      "MAY          float64\n",
      "JUN          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Check and fix data types ---\n",
    "\n",
    "# Reload merged datasets (to be safe)\n",
    "temp_path = \"../1_datasets/Cleaned_datasets/merged_temperature.csv\"\n",
    "rain_path = \"../1_datasets/Cleaned_datasets/merged_precipitation.csv\"\n",
    "\n",
    "df_temp = pd.read_csv(temp_path)\n",
    "df_rain = pd.read_csv(rain_path)\n",
    "\n",
    "# Convert data types\n",
    "def fix_dtypes(df):\n",
    "    df[\"REGION\"] = df[\"REGION\"].astype(str)\n",
    "    df[\"YEAR\"] = df[\"YEAR\"].astype(int)\n",
    "    \n",
    "    # Convert all monthly + ANN columns to float\n",
    "    month_cols = [c for c in df.columns if c not in [\"REGION\", \"YEAR\", \"LAT\", \"LON\", \"PARAMETER\"]]\n",
    "    df[month_cols] = df[month_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_temp = fix_dtypes(df_temp)\n",
    "df_rain = fix_dtypes(df_rain)\n",
    "\n",
    "print(\"Data types fixed.\")\n",
    "print(\"\\nTemperature data types:\")\n",
    "print(df_temp.dtypes.head(10))\n",
    "\n",
    "print(\"\\nRainfall data types:\")\n",
    "print(df_rain.dtypes.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0269a4",
   "metadata": {},
   "source": [
    "### Step 2: Handle missing or invalid values\n",
    "\n",
    "Even if the files looked clean, we’ll confirm no NaN, blank, or invalid numeric entries exist.\n",
    "We’ll also check for out-of-range values (e.g., rainfall < 0, or impossible temperatures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71482f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in temp dataset:\n",
      "Series([], dtype: int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amhx1\\AppData\\Local\\Temp\\ipykernel_12196\\2212108193.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[month_cols] = df[month_cols].applymap(lambda x: x if -50 <= x <= 60 else np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in rain dataset:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing and invalid values handled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amhx1\\AppData\\Local\\Temp\\ipykernel_12196\\2212108193.py:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[month_cols] = df[month_cols].applymap(lambda x: x if x >= 0 else np.nan)\n"
     ]
    }
   ],
   "source": [
    "def clean_missing_and_invalid(df, variable):\n",
    "    # Count missing\n",
    "    missing_summary = df.isna().sum()\n",
    "    print(f\"\\nMissing values in {variable} dataset:\")\n",
    "    print(missing_summary[missing_summary > 0])\n",
    "    \n",
    "    # Drop rows where YEAR, LAT, or LON are missing\n",
    "    df = df.dropna(subset=[\"YEAR\", \"LAT\", \"LON\"])\n",
    "    \n",
    "    # Replace negative precipitation (if any) with NaN\n",
    "    if variable == \"rain\":\n",
    "        month_cols = [c for c in df.columns if c not in [\"REGION\", \"YEAR\", \"LAT\", \"LON\", \"PARAMETER\"]]\n",
    "        df[month_cols] = df[month_cols].applymap(lambda x: x if x >= 0 else np.nan)\n",
    "    \n",
    "    # For temperature, drop extreme impossible values (< -50 or > 60)\n",
    "    if variable == \"temp\":\n",
    "        month_cols = [c for c in df.columns if c not in [\"REGION\", \"YEAR\", \"LAT\", \"LON\", \"PARAMETER\"]]\n",
    "        df[month_cols] = df[month_cols].applymap(lambda x: x if -50 <= x <= 60 else np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_temp = clean_missing_and_invalid(df_temp, \"temp\")\n",
    "df_rain = clean_missing_and_invalid(df_rain, \"rain\")\n",
    "\n",
    "print(\"\\nMissing and invalid values handled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7bd827",
   "metadata": {},
   "source": [
    "### Step 3: Check consistency across regions and years\n",
    "\n",
    "We’ll verify that:\n",
    "\n",
    "Every region covers roughly the same year range (1990–2024).\n",
    "\n",
    "No region is missing years or duplicated years.\n",
    "\n",
    "This ensures the dataset is consistent and ready for later aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c28afb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consistency check for Temperature dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>unique_years</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGION</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          min   max  unique_years\n",
       "REGION                           \n",
       "Central  1990  2024            35\n",
       "East     1990  2024            35\n",
       "North    1990  2024            35\n",
       "South    1990  2024            35\n",
       "West     1990  2024            35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checked consistency across regions and years.\n",
      "\n",
      "Consistency check for Rainfall dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>unique_years</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGION</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>1990</td>\n",
       "      <td>2024</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          min   max  unique_years\n",
       "REGION                           \n",
       "Central  1990  2024            35\n",
       "East     1990  2024            35\n",
       "North    1990  2024            35\n",
       "South    1990  2024            35\n",
       "West     1990  2024            35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checked consistency across regions and years.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_region_year_consistency(df, variable):\n",
    "    print(f\"\\nConsistency check for {variable} dataset:\")\n",
    "    summary = (\n",
    "        df.groupby(\"REGION\")[\"YEAR\"]\n",
    "        .agg([\"min\", \"max\", \"nunique\"])\n",
    "        .rename(columns={\"nunique\": \"unique_years\"})\n",
    "    )\n",
    "    display(summary)\n",
    "    print(\"\\nChecked consistency across regions and years.\")\n",
    "\n",
    "check_region_year_consistency(df_temp, \"Temperature\")\n",
    "check_region_year_consistency(df_rain, \"Rainfall\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a37b8",
   "metadata": {},
   "source": [
    "### Step 4: Summary and Data Export\n",
    "\n",
    "At this stage, both the temperature and rainfall datasets are:\n",
    "- Cleaned and merged across all regions (Central, East, North, South, West),\n",
    "- Consistent in year coverage (1990–2024),\n",
    "- Free of missing or invalid values,\n",
    "- Properly typed for numeric analysis.\n",
    "\n",
    "The next milestone (Milestone 3: Data Analysis) will focus on:\n",
    "- Aggregating regional data into national trends,\n",
    "- Visualizing temperature and rainfall changes over time,\n",
    "- Exploring correlations and seasonal patterns.\n",
    "\n",
    "Finally, we’ll export the cleaned datasets to the `Cleaned_datasets` folder for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785308cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned datasets successfully saved to 'Cleaned_datasets' folder.\n"
     ]
    }
   ],
   "source": [
    "# --- Save cleaned datasets for analysis ---\n",
    "clean_folder = \"../1_datasets/Cleaned_datasets\"\n",
    "\n",
    "os.makedirs(clean_folder, exist_ok=True)\n",
    "\n",
    "df_temp.to_csv(os.path.join(clean_folder, \"cleaned_temperature.csv\"), index=False)\n",
    "df_rain.to_csv(os.path.join(clean_folder, \"cleaned_rainfall.csv\"), index=False)\n",
    "\n",
    "\n",
    "print(\"Cleaned datasets successfully saved to 'Cleaned_datasets' folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6358605",
   "metadata": {},
   "source": [
    "### Merging Rainfall and Temperature Datasets by Region and Year\n",
    "\n",
    "In this step, we combine the two cleaned datasets:\n",
    "- **cleaned_rainfall.csv** – contains rainfall data by latitude, longitude, region, and year  \n",
    "- **cleaned_temperature.csv** – contains temperature data with the same structure  \n",
    "\n",
    "Since both datasets contain multiple latitude–longitude points within each region, we first **aggregate** them by `REGION` and `YEAR` to get the average monthly and annual values.  \n",
    "Then, we **merge** the two aggregated datasets using `REGION` and `YEAR` as keys.  \n",
    "Finally, we save the merged dataset into the `Final_dataset` folder for use in the analysis phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ae27fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved to final_dataset/final_merged_dataset.csv\n",
      "Shape: (175, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>LAT_RAIN</th>\n",
       "      <th>LON_RAIN</th>\n",
       "      <th>JAN_RAIN</th>\n",
       "      <th>FEB_RAIN</th>\n",
       "      <th>MAR_RAIN</th>\n",
       "      <th>APR_RAIN</th>\n",
       "      <th>MAY_RAIN</th>\n",
       "      <th>JUN_RAIN</th>\n",
       "      <th>...</th>\n",
       "      <th>APR_TEMP</th>\n",
       "      <th>MAY_TEMP</th>\n",
       "      <th>JUN_TEMP</th>\n",
       "      <th>JUL_TEMP</th>\n",
       "      <th>AUG_TEMP</th>\n",
       "      <th>SEP_TEMP</th>\n",
       "      <th>OCT_TEMP</th>\n",
       "      <th>NOV_TEMP</th>\n",
       "      <th>DEC_TEMP</th>\n",
       "      <th>ANN_TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central</td>\n",
       "      <td>1990</td>\n",
       "      <td>15.25</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>...</td>\n",
       "      <td>30.844667</td>\n",
       "      <td>33.960222</td>\n",
       "      <td>33.907000</td>\n",
       "      <td>32.037444</td>\n",
       "      <td>32.395111</td>\n",
       "      <td>32.977667</td>\n",
       "      <td>32.436444</td>\n",
       "      <td>29.210333</td>\n",
       "      <td>27.665444</td>\n",
       "      <td>28.028111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central</td>\n",
       "      <td>1991</td>\n",
       "      <td>15.25</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047333</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>...</td>\n",
       "      <td>33.137556</td>\n",
       "      <td>35.484000</td>\n",
       "      <td>34.458778</td>\n",
       "      <td>32.991222</td>\n",
       "      <td>31.911333</td>\n",
       "      <td>33.060556</td>\n",
       "      <td>32.269778</td>\n",
       "      <td>27.483222</td>\n",
       "      <td>22.874889</td>\n",
       "      <td>28.717444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Central</td>\n",
       "      <td>1992</td>\n",
       "      <td>15.25</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.292333</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.957444</td>\n",
       "      <td>32.862667</td>\n",
       "      <td>33.887667</td>\n",
       "      <td>32.620111</td>\n",
       "      <td>30.592222</td>\n",
       "      <td>31.677111</td>\n",
       "      <td>31.273667</td>\n",
       "      <td>26.608444</td>\n",
       "      <td>21.895444</td>\n",
       "      <td>26.553889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Central</td>\n",
       "      <td>1993</td>\n",
       "      <td>15.25</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.119333</td>\n",
       "      <td>0.646333</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>...</td>\n",
       "      <td>30.436333</td>\n",
       "      <td>32.704222</td>\n",
       "      <td>32.951444</td>\n",
       "      <td>31.131556</td>\n",
       "      <td>30.119111</td>\n",
       "      <td>30.464778</td>\n",
       "      <td>30.612667</td>\n",
       "      <td>28.435111</td>\n",
       "      <td>24.960222</td>\n",
       "      <td>26.655667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Central</td>\n",
       "      <td>1994</td>\n",
       "      <td>15.25</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389333</td>\n",
       "      <td>0.144667</td>\n",
       "      <td>...</td>\n",
       "      <td>31.737556</td>\n",
       "      <td>33.064222</td>\n",
       "      <td>33.141778</td>\n",
       "      <td>30.683111</td>\n",
       "      <td>30.624778</td>\n",
       "      <td>31.021778</td>\n",
       "      <td>31.593778</td>\n",
       "      <td>25.942444</td>\n",
       "      <td>22.093889</td>\n",
       "      <td>27.520667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    REGION  YEAR  LAT_RAIN  LON_RAIN  JAN_RAIN  FEB_RAIN  MAR_RAIN  APR_RAIN  \\\n",
       "0  Central  1990     15.25      32.5       0.0       0.0  0.000000  0.000000   \n",
       "1  Central  1991     15.25      32.5       0.0       0.0  0.000000  0.047333   \n",
       "2  Central  1992     15.25      32.5       0.0       0.0  0.000000  0.003000   \n",
       "3  Central  1993     15.25      32.5       0.0       0.0  0.000333  0.119333   \n",
       "4  Central  1994     15.25      32.5       0.0       0.0  0.000000  0.000000   \n",
       "\n",
       "   MAY_RAIN  JUN_RAIN  ...   APR_TEMP   MAY_TEMP   JUN_TEMP   JUL_TEMP  \\\n",
       "0  0.002000  0.026667  ...  30.844667  33.960222  33.907000  32.037444   \n",
       "1  0.216000  0.036667  ...  33.137556  35.484000  34.458778  32.991222   \n",
       "2  0.292333  0.145000  ...  30.957444  32.862667  33.887667  32.620111   \n",
       "3  0.646333  0.173667  ...  30.436333  32.704222  32.951444  31.131556   \n",
       "4  0.389333  0.144667  ...  31.737556  33.064222  33.141778  30.683111   \n",
       "\n",
       "    AUG_TEMP   SEP_TEMP   OCT_TEMP   NOV_TEMP   DEC_TEMP   ANN_TEMP  \n",
       "0  32.395111  32.977667  32.436444  29.210333  27.665444  28.028111  \n",
       "1  31.911333  33.060556  32.269778  27.483222  22.874889  28.717444  \n",
       "2  30.592222  31.677111  31.273667  26.608444  21.895444  26.553889  \n",
       "3  30.119111  30.464778  30.612667  28.435111  24.960222  26.655667  \n",
       "4  30.624778  31.021778  31.593778  25.942444  22.093889  27.520667  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load both datasets\n",
    "rain = pd.read_csv(\"../1_datasets/Cleaned_datasets/cleaned_rainfall.csv\")\n",
    "temp = pd.read_csv(\"../1_datasets/Cleaned_datasets/cleaned_temperature.csv\")\n",
    "final_folder = \"../1_datasets/Final_dataset\"\n",
    "\n",
    "# 1. Group by REGION and YEAR, taking the mean of numeric columns\n",
    "rain_region_year = rain.groupby(['REGION', 'YEAR']).mean(numeric_only=True).reset_index()\n",
    "temp_region_year = temp.groupby(['REGION', 'YEAR']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 2. Merge both datasets on REGION and YEAR\n",
    "merged = pd.merge(\n",
    "    rain_region_year, \n",
    "    temp_region_year, \n",
    "    on=['REGION', 'YEAR'], \n",
    "    suffixes=('_RAIN', '_TEMP')\n",
    ")\n",
    "# 3. Save the merged dataset\n",
    "merged.to_csv(os.path.join(final_folder, \"final_merged_data.csv\"), index=False)\n",
    "\n",
    "# 4. Print confirmation\n",
    "print(\"Merged dataset saved to final_dataset/final_merged_dataset.csv\")\n",
    "print(f\"Shape: {merged.shape}\")\n",
    "merged.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
