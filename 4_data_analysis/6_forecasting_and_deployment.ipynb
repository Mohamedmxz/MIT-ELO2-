{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6 â€” Forecasting and Deployment\n",
    "\n",
    "Purpose:\n",
    "- Train final model(s) on full training data or retrain using best params\n",
    "- Implement multi-step forecasting: recursive (iterative) and direct (example for H months)\n",
    "- Provide an inference helper that, given last observed months for a region, produces an H-month forecast\n",
    "- Save final forecasts and model artifacts to ../4_data_analysis/model_datasets/\n",
    "\n",
    "Notes:\n",
    "- This notebook expects model artifacts (final model) or best_params.json created by previous notebooks. It also reads the FE dataset for context.\n",
    "- Multi-step forecasting uses generated lag/roll features; the helper carefully updates lag/rolling features as it forecasts forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "out_dir = os.path.join('..','4_data_analysis','model_datasets')\n",
    "fe_path = os.path.join(out_dir, 'model_ready_dataset_fe.csv')\n",
    "model_path = os.path.join(out_dir, 'final_rf_model_joblib.pkl')\n",
    "best_params_path = os.path.join(out_dir, 'best_params.json')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(fe_path):\n",
    "    raise FileNotFoundError('FE dataset missing; run Notebook 3')\n",
    "df = pd.read_csv(fe_path)\n",
    "print('Loaded FE dataset shape:', df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load or train final model\n",
    "- If final_rf_model_joblib.pkl exists use it; otherwise retrain on all available data (excluding last 24 months per region) or on entire series depending on your preference for forecasting horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a saved model exists use it; else retrain using best_params or defaults\n",
    "if os.path.exists(model_path):\n",
    "    print('Loading saved model from', model_path)\n",
    "    model = joblib.load(model_path)\n",
    "else:\n",
    "    print('Saved model not found. Training a new RF on full data (excluding last 24 months per region)')\n",
    "    # split out last 24 months per region as holdout\n",
    "    def train_test_time_split(df, group_col='REGION', time_col='Time', test_periods=24):\n",
    "        train_parts, test_parts = [], []\n",
    "        for name, g in df.groupby(group_col):\n",
    "            g_sorted = g.sort_values(time_col).reset_index(drop=True)\n",
    "            train_parts.append(g_sorted.iloc[:-test_periods].copy())\n",
    "            test_parts.append(g_sorted.iloc[-test_periods:].copy())\n",
    "        return pd.concat(train_parts).reset_index(drop=True), pd.concat(test_parts).reset_index(drop=True)\n",
    "    train_df, test_df = train_test_time_split(df, test_periods=24)\n",
    "    features = [c for c in df.columns if c not in ['REGION','YEAR','Month','Month_Num','Rainfall','Temperature','Time']]\n",
    "    features = ['YEAR','Time','Month_sin','Month_cos'] + [c for c in features if ('lag' in c or '_roll' in c)]\n",
    "    features = [c for c in features if c in train_df.columns]\n",
    "    X_tr = train_df[features]\n",
    "    y_tr = train_df['Rainfall']\n",
    "    # use best params if available\n",
    "    if os.path.exists(best_params_path):\n",
    "        import json\n",
    "        with open(best_params_path) as f:\n",
    "            best = json.load(f)\n",
    "        rf_params = best.get('rf_raw') or best.get('rf_log1p') or {'n_estimators':200, 'max_depth':10}\n",
    "    else:\n",
    "        rf_params = {'n_estimators':200, 'max_depth':10}\n",
    "    rf_params = {k:v for k,v in rf_params.items() if k in ['n_estimators','max_depth','max_features']}\n",
    "    model = RandomForestRegressor(n_jobs=-1, random_state=42, **rf_params)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    joblib.dump(model, model_path)\n",
    "    print('Trained and saved model to', model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-step forecasting helper (recursive):\n",
    "- Input: last observed rows for a single region (must include features and last observed Rainfall/Temperature)\n",
    "- The helper iteratively constructs new rows for each forecast step, updating lag and rolling columns as it goes.\n",
    "- Example uses H=6 months; adjust as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_forecast_region(model, region_df, H=6, features=None, LAGS=[1,2,3,12], roll_windows={'roll3':3,'roll12':12}):\n",
    "    # region_df should be sorted by Time ascending and contain the latest observed row at the end\n",
    "    res_rows = []\n",
    "    cur = region_df.copy().reset_index(drop=True)\n",
    "    last_time = cur['Time'].iloc[-1]\n",
    "    for h in range(1, H+1):\n",
    "        new_time = last_time + h\n",
    "        # Build new row dict starting from last observed features that are static/known (REGION, YEAR increment, Month_Num rotate)\n",
    "        last_row = cur.iloc[-1].to_dict()\n",
    "        new_row = last_row.copy()\n",
    "        new_row['Time'] = new_time\n",
    "        # increment month/year\n",
    "        prev_month = int(last_row['Month_Num'])\n",
    "        new_month = ((prev_month + h - 1) % 12) + 1\n",
    "        # naive YEAR increment when month wraps (approx)\n",
    "        year_inc = (prev_month + h - 1) // 12\n",
    "        new_row['Month_Num'] = new_month\n",
    "        new_row['YEAR'] = int(new_row['YEAR']) + year_inc\n",
    "        # update cyclical\n",
    "        new_row['Month_sin'] = np.sin(2 * np.pi * (new_row['Month_Num'] / 12))\n",
    "        new_row['Month_cos'] = np.cos(2 * np.pi * (new_row['Month_Num'] / 12))\n",
    "\n",
    "        # update lag columns from cur (use the previously observed and forecasted values in cur)\n",
    "        for lag in LAGS:\n",
    "            col = f'Rainfall_lag_{lag}'\n",
    "            # lag 1 is previous month: take last row's Rainfall for lag 1 at h=1, else from cur tail\n",
    "            idx = len(cur) - lag\n",
    "            if idx >= 0:\n",
    "                new_row[col] = cur.iloc[idx]['Rainfall']\n",
    "            else:\n",
    "                new_row[col] = np.nan\n",
    "        # For Temperature lags if present, shift similarly\n",
    "        for lag in LAGS:\n",
    "            col = f'Temperature_lag_{lag}'\n",
    "            idx = len(cur) - lag\n",
    "            if idx >= 0:\n",
    "                new_row[col] = cur.iloc[idx]['Temperature']\n",
    "            else:\n",
    "                new_row[col] = np.nan\n",
    "\n",
    "        # Rolling features: recompute from cur (which grows as we append forecasts)\n",
    "        for label, window in roll_windows.items():\n",
    "            rcol = f'Rainfall_{label}'\n",
    "            tcol = f'Temperature_{label}'\n",
    "            # compute using shift(1).rolling(window).mean over the Rainfall series in cur\n",
    "            s = pd.Series(cur['Rainfall'].values)\n",
    "            # use only available previous values\n",
    "            if len(s) >= window:\n",
    "                val = s.shift(1).rolling(window=window, min_periods=window).mean().iloc[-1]\n",
    "            else:\n",
    "                val = np.nan\n",
    "            new_row[rcol] = val\n",
    "            sT = pd.Series(cur['Temperature'].values)\n",
    "            if len(sT) >= window:\n",
    "                valT = sT.shift(1).rolling(window=window, min_periods=window).mean().iloc[-1]\n",
    "            else:\n",
    "                valT = np.nan\n",
    "            new_row[tcol] = valT\n",
    "\n",
    "        # Create dataframe for prediction (features ordering)\n",
    "        pred_df = pd.DataFrame([new_row])\n",
    "        # ensure features list\n",
    "        if features is None:\n",
    "            feat_cols = [c for c in pred_df.columns if c not in ['REGION','YEAR','Month','Month_Num','Rainfall','Temperature','Time']]\n",
    "        else:\n",
    "            feat_cols = features\n",
    "        feat_cols = [c for c in feat_cols if c in pred_df.columns]\n",
    "        X_pred = pred_df[feat_cols]\n",
    "        yhat = model.predict(X_pred)[0]\n",
    "        yhat = max(0.0, yhat)  # clip\n",
    "        new_row['Rainfall'] = yhat\n",
    "        # Temperature forecast: naive carry-forward of last observed temperature if no model for temp available\n",
    "        if 'Temperature' not in pred_df.columns or pd.isna(new_row.get('Temperature', np.nan)):\n",
    "            new_row['Temperature'] = cur.iloc[-1]['Temperature']\n",
    "        # append new row to cur so next iter uses updated history\n",
    "        cur = cur.append(new_row, ignore_index=True)\n",
    "        res_rows.append(new_row)\n",
    "    return pd.DataFrame(res_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: forecast next 6 months for one region and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a region\n",
    "region = df['REGION'].unique()[0]\n",
    "print('Forecast example for region:', region)\n",
    "reg_df = df[df['REGION']==region].sort_values('Time')\n",
    "feat_cols = [c for c in df.columns if c not in ['REGION','YEAR','Month','Month_Num','Rainfall','Temperature','Time']]\n",
    "feat_cols = ['YEAR','Time','Month_sin','Month_cos'] + [c for c in feat_cols if ('lag' in c or '_roll' in c)]\n",
    "feat_cols = [c for c in feat_cols if c in df.columns]\n",
    "\n",
    "fc = recursive_forecast_region(model, reg_df, H=6, features=feat_cols)\n",
    "print('Forecast output:')\n",
    "display(fc)\n",
    "out_fc_path = os.path.join(out_dir, f'forecast_{region}_H6.csv')\n",
    "fc.to_csv(out_fc_path, index=False)\n",
    "print('Saved forecast to', out_fc_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch forecasts for all regions (H=6) and save a combined CSV.\n",
    "This may take some time depending on number of regions; adjust H as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fcs = []\n",
    "for region in df['REGION'].unique():\n",
    "    reg_df = df[df['REGION']==region].sort_values('Time')\n",
    "    try:\n",
    "        fc = recursive_forecast_region(model, reg_df, H=6, features=feat_cols)\n",
    "        fc['REGION'] = region\n",
    "        all_fcs.append(fc)\n",
    "    except Exception as e:\n",
    "        print('Failed to forecast region', region, 'error:', e)\n",
    "\n",
    "if all_fcs:\n",
    "    all_fc_df = pd.concat(all_fcs, ignore_index=True)\n",
    "    \n",
    "    all_fc_path = os.path.join(out_dir, 'forecasts_all_regions_H6.csv')\n",
    "    all_fc_df.to_csv(all_fc_path, index=False)\n",
    "    print('Saved combined forecasts to', all_fc_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap-up and next steps\n",
    "- The recursive helper demonstrates how to produce multi-step forecasts while updating lags and rolling features.\n",
    "- For production: consider retraining final model on the entire available history (no holdout) before deploying forecasts; or use ensemble of models.\n",
    "- To produce prediction intervals consider bootstrap residuals or use probabilistic learners (quantile regressor, XGB quantile, or use Tweedie objective for XGBoost).\n",
    "- Save model(s) and forecast outputs with metadata (training period, model params) so stakeholders can reproduce results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
